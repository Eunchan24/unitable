# Towards a Unified Table Foundation Model

1.  ðŸ“ˆ [High-Performance Transformers for Table Structure Recognition Need Early Convolutions](https://arxiv.org/abs/2311.05565). ShengYun Peng, Seongmin Lee, Xiaojing Wang, Rajarajeswari Balasubramaniyan, Duen Horng Chau. In *NeurIPS Second Table Representation Learning Workshop*, 2023. (Oral)
2.  ðŸš€ Self-Supervised Pretraining for Table Structure Recognition Transformer. ShengYun Peng, Seongmin Lee, Xiaojing Wang, Rajarajeswari Balasubramaniyan, Duen Horng Chau. In *AAAI Scientific Document Understanding Workshop*, 2024. (Oral)
3.  ðŸ†• UniTable: Towards a Unified Framework for Table Structure Recognition via Self-Supervised Pretraining. ShengYun Peng, Seongmin Lee, Xiaojing Wang, Rajarajeswari Balasubramaniyan, Duen Horng Chau. Coming soon!

> This repo includes code for linear projection Transformers. For convolutional stem (early convolution) Transformers, please check out our [tsr-convstem repo](https://github.com/poloclub/tsr-convstem). 

# Try it out
We provide a [Jupyter Notebook](https://github.com/poloclub/unitable/blob/main/notebooks/full_pipeline.ipynb) that fully digitalize your tables with a single click.
Simply upload your tabular image by overwriting the <code>image_path</code> and proceed to run through the notebook.

# News
`Feb. 2024` - We presented "Self-Supervised Pretraining" paper at AAAI'24

`Jan. 2024` - "Self-Supervised Pretraining" paper selected as [oral](https://sites.google.com/view/sdu-aaai24/schedule?authuser=0)

`Dec. 2023` - "Self-Supervised Pretraining" paper accepted by [AAAI'24 Scientific Document Understanding Workshop](https://sites.google.com/view/sdu-aaai24/schedule?authuser=0)

`Dec. 2023` - We presented "Early Convolutions" paper at NeurIPS'23 - [link](https://x.com/RealAnthonyPeng/status/1735715161476866135?s=20)

`Oct. 2023` - "Early Convolutions" paper selected as [oral](https://table-representation-learning.github.io/#accepted-papers)

`Oct. 2023` - "Early Convolutions" paper accepted by [NeurIPS'23 Table Representation Learning Workshop](https://table-representation-learning.github.io/)

# Get Started
Set up virtual environment
```bash
make .venv_done
```

# Training, Testing & Evaluation
Coming soon!

## Citation
```bibtex
@article{peng2024unitable,
  title={UniTable: Towards a Unified Framework for Table Structure Recognition via Self-Supervised Pretraining},
  author={Peng, ShengYun and Lee, Seongmin and Wang, Xiaojing and Balasubramaniyan, Rajarajeswari and Chau, Duen Horng},
  journal={arXiv preprint},
  year={2024}
}

@article{peng2024self,
  title={Self-Supervised Pretraining for Table Structure Recognition Transformer},
  author={Peng, ShengYun and Lee, Seongmin and Wang, Xiaojing and Balasubramaniyan, Rajarajeswari and Chau, Duen Horng},
  journal={arXiv preprint},
  year={2024}
}

@inproceedings{peng2023high,
  title={High-Performance Transformers for Table Structure Recognition Need Early Convolutions},
  author={Peng, Anthony and Lee, Seongmin and Wang, Xiaojing and Balasubramaniyan, Rajarajeswari Raji and Chau, Duen Horng},
  booktitle={NeurIPS 2023 Second Table Representation Learning Workshop},
  year={2023}
}
```
## Contact
If you have any questions, feel free to contact [Anthony Peng](https://shengyun-peng.github.io/) (CS PhD @Georgia Tech).

